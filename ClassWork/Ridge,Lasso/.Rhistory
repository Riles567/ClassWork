#Getting resid^2 for the test dataset
resid2 = (originaly[holdout]-predict.test)^2
#Computing RMSE and placing result into output vector
output[i] = sqrt(mean(resid2))
}
#Return RMSE values and their average over b iterations
list(RMSE_Vector=output,Avg_RMSE=mean(output))
}
mc.cv <- function(lm.object,data,p=0.33,b=100){
#Getting the number of rows in data
n=dim(data)[1]
#How many observations should be in holdout sample
np=floor(p*n)
#Getting a copy of the orginal response vector
originaly = lm.object$model[,1]
#Getting an output vector to store RMSE on each of the b iterations
output = rep(0,n)
#The loop for repeated iterations
for(i in 1:b){
#Getting the observations for the holdout sample
holdout=sample(1:n,np,replace=F)
#Fitting the model on the training dataset
fit = lm(formula(lm.object),data=data[-holdout,])
#Getting the predicted values for the test dataset
predict.test = predict(fit,newdata=data[holdout,])
#Getting resid^2 for the test dataset
resid2 = (originaly[holdout]-predict.test)^2
#Computing RMSE and placing result into output vector
output[i] = sqrt(mean(resid2))
}
#Return RMSE values and their average over b iterations
list(RMSE_Vector=output,Avg_RMSE=mean(output))
}
read.csv("C:/Users/yz9186ci/Desktop/Stat 360/data/Grandfather_Clocks.csv")
grand_clock <- read.csv("C:/Users/yz9186ci/Desktop/Stat 360/data/Grandfather_Clocks.csv")
fit <- lm(Price~(Age + Number_Bidders), data = grand_clock)
summary(fit)
predict.jackknife(fit,grand_clock)
predict.jackknife <- function(lm.object,data){
n <- dim(data)[1]
originaly <- lm.object$model[,1]
output = rep(0,n)
for (i in 1:n) {
fit.minus <- lm(formula(lm.object), data = data[-i,] )
predictedy <- predict(fit.minus, newdata = data[i,])
output[i] <- (originaly[i]- predictedy)^2
}
list(SquaredResids = output, Jackknife_RMSE = sqrt(mean(output)))
}
predict.jackknife(fit,grand_clock)
dim(grand_clock)
holdout <- sample(1:32,10,replace = F)
holdout
fit.train <- lm(Price~(Age+Number_Bidders), data = grand_clock[-holdout,])
summary(fit.train)
predict.test <- predict(fit.train, newdata = grand_clock[holdout,])
resid.test <- (grand_clock[holdout,2] - predict.test)
sqrt(mean((resid.test^2)))
MC_RMSE <- mc.cv(fit,grand_clock)
MC_RMSE
mc.cv(fit,grand_clock,p=.25,b=1000)
mc.cv(fit,grand_clock,p=0,b=1000)
mc.cv(fit,grand_clock,p=.1,b=1000)
mc.cv(fit,grand_clock,p=.75,b=1000)
mc.cv(fit,grand_clock,p=.01,b=1000)
mc.cv(fit,grand_clock,p=.25,b=1000)
mc.cv(fit,grand_clock,p=.25,b=1000)
View(resid.test)
mc.cv(fit,grand_clock,p=.20,b=100)
View(resid.test)
mc.cv(fit,grand_clock,p=.5,b=1000)
mc.cv(fit,grand_clock,p=.4,b=1000)
hist(MC_RMSE$RMSE_Vector)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("mixOmics")
nenana <- read.csv("C:/Users/yz9186ci/Desktop/Stat 360/data/nenana.csv")
library(dplyr)
library(ggplot2)
(nenana
%>% mutate(Distance_Above_Changepoint = case_shen((Year - 1970) >0 ~ (Year- 1970), (Year - 1970) <= 0 ~ 0
)
)
) -> nenana
(nenana
%>% mutate(Distance_Above_Changepoint = case_when((Year - 1970) >0 ~ (Year- 1970), (Year - 1970) <= 0 ~ 0
)
)
) -> nenana
nenana_fit <- lm(DayIntoYear ~ Year + Distance_Above_Changepoint, data = nenana)
summary(nenana_fit)
(nenana
%>% mutate(Predicted = predict(nenana_fit, newdata = nenana))
%>% mutate(Residuals = (DayIntoYear - Predicted))
)-> nenana
ggplot(NenanaData,mapping=aes(x=Year,y=DayIntoYear)) +
geom_point() +
geom_smooth(method="loess",span = 1,se=FALSE, col="black") +
theme_classic()
ggplot(nenana,mapping=aes(x=Year,y=DayIntoYear)) +
geom_point() +
geom_smooth(method="loess",span = 1,se=FALSE, col="black") +
theme_classic()
#Plotting residuals with Change Point = 1970
ggplot(nenana,mapping=aes(x=Predicted,y=Residuals)) +
geom_point() +
geom_smooth(method="loess",se=FALSE) +
ylim(-20,20) +
theme_classic()
#Plotting predicted with Change Point = 1970
ggplot(nenana,mapping=aes(x=Year,y=DayIntoYear)) +
geom_point() +
geom_line(mapping=aes(x=Year,y=Predicted)) +
theme_classic()
#Plotting residuals with Change Point = 1970
ggplot(nenana,mapping=aes(x=Predicted,y=Residuals)) +
geom_point() +
geom_smooth(method="loess",se=FALSE) +
ylim(-20,20) +
theme_classic()
#Plotting predicted with Change Point = 1970
ggplot(nenana,mapping=aes(x=Year,y=DayIntoYear)) +
geom_point() +
geom_line(mapping=aes(x=Year,y=Predicted)) +
theme_classic()
(nenana
%>% mutate(Distance_Above_Changepoint = case_when((Year - 1965) >0 ~ (Year- 1965), (Year - 1965) <= 0 ~ 0
)
)
) -> nenana
nenana_fit <- lm(DayIntoYear ~ Year + Distance_Above_Changepoint, data = nenana)
summary(nenana_fit)
(DataChangePoint
%>% rowwise()
%>% mutate (Sigma = (NenanaData
%>% mutate(Distance_Above_ChangePoint = case_when( (Year - ChangePoint)  > 0 ~ (Year - ChangePoint),
(Year - ChangePoint) <= 0 ~ 0
)
)
%>% lm(formula = DayIntoYear ~ Year + Distance_Above_ChangePoint)
%>% summary
%>% getElement("sigma")
))
) -> DataChangePoint
(DataChangePoint
%>% rowwise()
%>% mutate (Sigma = (nenana
%>% mutate(Distance_Above_ChangePoint = case_when( (Year - ChangePoint)  > 0 ~ (Year - ChangePoint),
(Year - ChangePoint) <= 0 ~ 0
)
)
%>% lm(formula = DayIntoYear ~ Year + Distance_Above_ChangePoint)
%>% summary
%>% getElement("sigma")
))
) -> DataChangePoint
DataChangePoint <- data.frame(ChangePoint = seq(from=1960,to=1975,by=1))
(DataChangePoint
%>% rowwise()
%>% mutate (Sigma = (nenana
%>% mutate(Distance_Above_ChangePoint = case_when( (Year - ChangePoint)  > 0 ~ (Year - ChangePoint),
(Year - ChangePoint) <= 0 ~ 0
)
)
%>% lm(formula = DayIntoYear ~ Year + Distance_Above_ChangePoint)
%>% summary
%>% getElement("sigma")
))
) -> DataChangePoint
ggplot(DataChangePoint, mapping = aes(x = Changepoint, y= Sigma))+
geom_line()+
geom_classic()
ggplot(DataChangePoint, mapping = aes(x = Changepoint, y= Sigma))+
geom_line()+
theme_classic()
ggplot(DataChangePoint, mapping = aes(x = ChangePoint, y= Sigma))+
geom_line()+
theme_classic()
(nenana
%>% mutate(Distance_Above_Changepoint = case_when((Year - 1964) >0 ~ (Year- 1964), (Year - 1964) <= 0 ~ 0
)
)
) -> nenana
nenana_fit <- lm(DayIntoYear ~ Year + Distance_Above_Changepoint, data = nenana)
summary(nenana_fit)
install.packages("segmented")
library(segmented)
Nenana <- lm(DayIntoYear, data = nenana)
Nenana <- lm(DayIntoYear ~ Year, data = nenana)
seg_fit <- segmented(Nenana, seg.Z = ~Year, npsi = 1)
summary(seg_fit)
seg_fit <- segmented(Nenana, seg.Z = ~Year, npsi = 5)
summary(seg_fit)
seg_fit <- segmented(Nenana, seg.Z = ~Year, npsi = 2)
seg_fit <- segmented(Nenana, seg.Z = ~Year, npsi = 1)
summary(seg_fit)
setwd("C:/Users/yz9186ci/Desktop/DSCI425/ClassWork/ClassWork/Ridge,Lasso")
library(ISLR)
library(genridge)
install.packages("ISLR")
library(genridge)
library(ISLR)
install.packages("genridge")
library(genridge)
install.packages("glmnet")
data(College)
College2 <- data.frame(PctAccept = 100*(College$Accept/College$Apps), College[,-c(2:3)])
attach(College)
College4 = data.frame(logApps=log(Apps),Private,logAcc=log(Accept),logEnr=log(Enroll),Top10perc,
Top25perc,logFull=log(F.Undergrad),logPart=log(P.Undergrad),Outstate,Room.Board,Books,Personal,PhD,Terminal,S.F.Ratio,perc.alumni,logExp=log(Expend),Grad.Rate)
detach(College)
nrow(College2)
set.seed(1)
sam <- sample(1:777, size = floor(.667*777), replace = F)
college.train <- College2[sam,]
college.test <- College2[-sam,]
names(College2)
X = model.matrix(PctAccept~.,data=college.train)[,-1]
y = college.train$PctAccept
Xs = scale(X)
College2.temp = data.frame(y,Xs)
PA.ols = lm(y~Xs,data=College2.temp,subset=sam)
ypred = predict(PA.ols,newdata=College2.temp[-sam,])
grid = 10^seq(10,-2,length=200)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
X = model.matrix(PctAccept~.,data=College2)[,-1]
y = College2$PctAccept
Xs = scale(X)
College2.temp = data.frame(y,Xs)
sam = sample(1:length(y),floor(.6667*length(y)),replace=F)
PA.ols = lm(y~Xs,data=College2.temp,subset=sam)
ypred = predict(PA.ols,newdata=College2.temp[-sam,])
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
grid = 10^seq(10,-2,length=200)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
library(glmnet)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=grid)
plot(ridge.mod)
plot(ridge.mod,xvar=”lambda”)
plot(ridge.mod,xvar="lambda")
PA.ols = lm(y~Xs,data=college.train)
ypred = predict(PA.ols,newdata=college.test)
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
sam <- sample(1:777, size = floor(.667*777), replace = F)
college.train <- College2[sam,]
college.test <- College2[-sam,]
X = model.matrix(PctAccept~.,data=College2)[,-1]
y = College2$PctAccept
Xs = scale(X)
College2.temp = data.frame(y,Xs)
sam = sample(1:length(y),floor(.6667*length(y)),replace=F)
PA.ols = lm(y~Xs,data=college.train)
ypred = predict(PA.ols,newdata=college.test)
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
sam <- sample(1:777, size = floor(.667*777), replace = F)
college.train <- College2[sam,]
college.test <- College2[-sam,]
names(College2)
X = model.matrix(PctAccept~.,data=College2)[,-1]
y = College2$PctAccept
Xs = scale(X)
College2.temp = data.frame(y,Xs)
sam = sample(1:length(y),floor(.6667*length(y)),replace=F)
PA.ols = lm(y~Xs,data=college.train)
ypred = predict(PA.ols,newdata=college.test)
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
grid = 10^seq(10,-2,length=200)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=grid)
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
ridge.mod = glmnet(Xs[sam,],y[sam,],alpha=0,lambda=grid)
cv.out = cv.glmnet(X,y,alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
ridge.mod = glmnet(Xs,y,alpha=0,lambda=bestlam)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=bestlam)
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
cbind(coef(ridge.mod), coef(lasso.mod), coef(PA.ols))
plot(y[-sam],predict(modelname,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
plot(y[-sam],predict(ridge.mod,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
plot(y[-sam],predict(lasso.mod,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
ridge.pred <- predict(ridge.mod, newx = X[-sam])
test <- (-sam)
ridge.pred <- predict(ridge.mod, newx = X[test])
ridg.best <- glmnet(X[sam,],y[sam],alpha = 0, lambda = bestlam)
ridge.pred <- predict(ridg.best, newx = X[test,])
RMSEP.rid <- sqrt(mean((y[-sam]-ridge.pred)^2))
RMSEP.rid
lasso.best <- glmnet(X[sam,],y[sam],alpha = 1, lambda = bestlam)
lasso.pred <- predict(lasso.best, newx = X[test,])
RMSEP.rid <- sqrt(mean((y[-sam]-lasso.pred)^2))
RMSEP.rid
MLR.ssmc = function(fit,p=.667,M=100) {
RMSEP = rep(0,M)
MAEP = rep(0,M)
MAPEP = rep(0,M)
y = fit$model[,1]
x = fit$model[,-1]
data = fit$model
n = nrow(data)
for (i in 1:M) {
ss = floor(n*p)
sam = sample(1:n,ss,replace=F)
fit2 = lm(formula(fit),data=data[sam,])
ypred = predict(fit2,newdata=x[-sam,])
RMSEP[i] = sqrt(mean((y[-sam]-ypred)^2))
MAEP[i] = mean(abs(y[-sam]-ypred))
yp = ypred[y[-sam]!=0]
ya = y[-sam][y[-sam]!=0]
MAPEP[i]=mean(abs(yp-ya)/ya)
}
cat("RMSEP =",mean(RMSEP),"  MAEP=",mean(MAEP),"  MAPEP=",mean(MAPEP))
cv = return(data.frame(RMSEP=RMSEP,MAEP=MAEP,MAPEP=MAPEP))
}
glmnet.ssmc = function(X,y,p=.667,M=100,alpha=1,lambda=1) {
RMSEP = rep(0,M)
MAEP = rep(0,M)
MAPEP = rep(0,M)
n = nrow(X)
for (i in 1:M) {
ss = floor(n*p)
sam = sample(1:n,ss,replace=F)
fit = glmnet(X[sam,],y[sam],lambda=lambda,alpha=alpha)
ypred = predict(fit,newx=X[-sam,])
RMSEP[i] = sqrt(mean((y[-sam]-ypred)^2))
MAEP[i] = mean(abs(y[-sam]-ypred))
yp = ypred[y[-sam]!=0]
ya = y[-sam][y[-sam]!=0]
MAPEP[i]=mean(abs(yp-ya)/ya)
}
cat("RMSEP =",mean(RMSEP),"  MAEP=",mean(MAEP),"  MAPEP=",mean(MAPEP))
cv = return(data.frame(RMSEP=RMSEP,MAEP=MAEP,MAPEP=MAPEP))
}
OLS.MC <- MLR.ssmc(X,y, M= 100, alpha = 0, lambda = bestlam)
OLS.MC <- MLR.ssmc(PA.ols, m =1000)
OLS.MC <- MLR.ssmc(PA.ols, M =1000)
ridge.MC <- glmnet.ssmc(X,y,alpha = 0,M = 1000, lambda = bestlam)
lasso.MC <- glmnet.ssmc(X,y, alpha = 1, M = 1000, lambda = bestlam)
PA.step <- step(PA.ols)
OLS.MC <- MLR.ssmc(PA.step, M =1000)
X = model.matrix(PctAccept~.,data=College2)[,-1]
y = College2$PctAccept
Xs = scale(X)
College2.temp = data.frame(y,Xs)
sam = sample(1:length(y),floor(.6667*length(y)),replace=F)
PA.ols = lm(y~Xs,data=college.train)
PA.step <- step(PA.ols)
ypred = predict(PA.ols,newdata=college.test)
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
OLS.MC <- MLR.ssmc(PA.ols, M =1000)
#I
set.seed(1)
train <- sample(1:777, size = floor(.667*777), replace = F)
test <- (-train)
college.train <- College4[train,]
college.test <- College4[test,]
X = model.matrix(PctAccept~.,data=College4)[,-1]
College4 = data.frame(logApps=log(Apps),Private,logAcc=log(Accept),logEnr=log(Enroll),Top10perc,
Top25perc,logFull=log(F.Undergrad),logPart=log(P.Undergrad),Outstate,Room.Board,Books,Personal,PhD,Terminal,S.F.Ratio,perc.alumni,logExp=log(Expend),Grad.Rate)
College4 = data.frame(logApps=log(Apps),Private,logAcc=log(Accept),logEnr=log(Enroll),Top10perc,
Top25perc,logFull=log(F.Undergrad),logPart=log(P.Undergrad),Outstate,Room.Board,Books,Personal,PhD,Terminal,S.F.Ratio,perc.alumni,logExp=log(Expend),Grad.Rate)
X = model.matrix(logApps~.,data=College2)[,-1]
College4 = data.frame(logApps=log(Apps),Private,logAcc=log(Accept),logEnr=log(Enroll),Top10perc,
Top25perc,logFull=log(F.Undergrad),logPart=log(P.Undergrad),Outstate,Room.Board,Books,Personal,PhD,Terminal,S.F.Ratio,perc.alumni,logExp=log(Expend),Grad.Rate)
attach(College)
College4 = data.frame(logApps=log(Apps),Private,logAcc=log(Accept),logEnr=log(Enroll),Top10perc,
Top25perc,logFull=log(F.Undergrad),logPart=log(P.Undergrad),Outstate,Room.Board,Books,Personal,PhD,Terminal,S.F.Ratio,perc.alumni,logExp=log(Expend),Grad.Rate)
detach(College)
X = model.matrix(logApps~.,data=College4)[,-1]
y = College4$logApps
Xs = scale(X)
College4.temp = data.frame(y,Xs)
sam = sample(1:length(y),floor(.6667*length(y)),replace=F)
c4.ols = lm(y~Xs,data=college.train)
c4.step <- step(PA.ols)
ypred = predict(PA.ols,newdata=college.test)
c4.step <- step(c4.ols)
ypred = predict(c4.ols,newdata=college.test)
RMSEP.ols = sqrt(mean((y[-sam]-ypred)^2))
RMSEP.ols
grid = 10^seq(10,-2,length=200)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=grid)
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
cv.out = cv.glmnet(X,y,alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
ridge.mod = glmnet(Xs,y,alpha=0,lambda=bestlam)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=bestlam)
cbind(coef(ridge.mod), coef(lasso.mod), coef(PA.ols))
plot(y[-sam],predict(lasso.mod,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
plot(y[-sam],predict(ridge.mod,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
ridg.best <- glmnet(X[sam,],y[sam],alpha = 0, lambda = bestlam)
ridge.pred <- predict(ridg.best, newx = X[test,])
RMSEP.rid <- sqrt(mean((y[-sam]-ridge.pred)^2))
RMSEP.rid
lasso.best <- glmnet(X[sam,],y[sam],alpha = 1, lambda = bestlam)
lasso.pred <- predict(lasso.best, newx = X[test,])
RMSEP.rid <- sqrt(mean((y[-sam]-lasso.pred)^2))
RMSEP.rid
C
OLS.MC <- MLR.ssmc(PA.ols, M =1000)
ridge.MC <- glmnet.ssmc(X,y,alpha = 0,M = 1000, lambda = bestlam)
OLS.MC <- MLR.ssmc(c4.ols, M =1000)
ridge.MC <- glmnet.ssmc(X,y,alpha = 0,M = 1000, lambda = bestlam)
lasso.MC <- glmnet.ssmc(X,y, alpha = 1, M = 1000, lambda = bestlam)
lu <- read.csv("Lu2004")
lu <- read.csv("Lu2004.csv")
# problem 2
names(lu)
X = model.matrix(Age~.,data=lu)[,-1]
y = lu$Age
Xs = scale(X)
grid = 10^seq(10,-2,length=200)
ridge.mod = glmnet(Xs,y,alpha=0,lambda=grid)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=grid)
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
plot(ridge.mod)
par(mfrow = c(2,2))
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
plot(ridge.mod,xvar="lambda",title(ridge))
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(ridge.mod)
plot(ridge.mod,xvar="lambda")
plot(lasso.mod)
plot(lasso.mod,xvar = "lambda")
cv.out = cv.glmnet(X,y,alpha=0)
par(mfrow = c(1,1))
cv.out = cv.glmnet(X,y,alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
cv.out = cv.glmnet(X,y,alpha=1)
plot(cv.out)
bestlam.las = cv.out$lambda.min
bestlam.las
cv.out = cv.glmnet(X,y,alpha=1)
plot(cv.out)
bestlam.rid <= cv.out$lambda.min
bestlam.rid <- cv.out$lambda.min
ridge.mod = glmnet(Xs,y,alpha=0,lambda=bestlam.rid)
lasso.mod = glmnet(Xs,y,alpha=1,lambda=bestlam.las)
plot(y[-sam],predict(ridge.mod,newx=X),xlab="Test y-values",ylab="Predicted Test y-values")
[-sam,]
plot(y[-sam],predict(ridge.mod,newx=X[-sam,]),xlab="Test y-values",ylab="Predicted Test y-values")
nrow(lu)
sam <- sample(1:30, size = floor(.667*30), replace = F)
train <- sample(1:30, size = floor(.667*30), replace = F)
test <- (-train)
plot(y[test],predict(ridge.mod,newx=X[test,]),xlab="Test y-values",ylab="Predicted Test y-values")
plot(y[test],predict(lasso.mod,newx=X[test,]),xlab="Test y-values",ylab="Predicted Test y-values")
summary(lasso.mod)
summary(lasso.mod$beta)
coef(lasso.mod)
ridge.MC <- glmnet.ssmc(X,y,p = .75,alpha = 0,M = 1000, lambda = bestlam.rid)
lasso.MC <- glmnet.ssmc(X,y,p = .75, alpha = 1, M = 1000, lambda = bestlam.las)
bf.en <- glmnet(X,y,alpha = .5)
cv.en <- cv.glmnet(X,y,alpha = .5)
bestlam.en <- cv.en$lambda.min
en.results <- glmnet.ssmc(X,y,M= 1000, alpha = .05, lambda = bestlam.en)
en.results <- glmnet.ssmc(X,y,M= 1000, alpha = .5, lambda = bestlam.en)
bf.en <- glmnet(X,y,alpha = .25)
cv.en <- cv.glmnet(X,y,alpha = .25)
bestlam.en <- cv.en$lambda.min
en.results <- glmnet.ssmc(X,y,M= 1000, alpha = .25, lambda = bestlam.en)
bf.en <- glmnet(X,y,alpha = .1)
cv.en <- cv.glmnet(X,y,alpha = .1)
bestlam.en <- cv.en$lambda.min
en.results <- glmnet.ssmc(X,y,M= 1000, alpha = .1, lambda = bestlam.en)
cv.out = cv.glmnet(X,y,alpha=0)
plot(cv.out)
X = model.matrix(logApps~.,data=College4)[,-1]
y = College4$logApps
Xs = scale(X)
cv.out = cv.glmnet(X,y,alpha=0)
plot(cv.out)
cv.out = cv.glmnet(X,y,alpha=1)
cv.out = cv.glmnet(X,y,alpha=0)
cv.out = cv.glmnet(X,y,alpha=1)
plot(cv.out)
X = model.matrix(logApps~.,data=College2)[,-1]
y = College2$PctAccept
Xs = scale(X)
cv.out = cv.glmnet(X,y,alpha=1)
plot(cv.out)
